With reference from: 
https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model
https://www.youtube.com/watch?v=cvyDYdI2nEI

REQUIREMENTS:
PROTOC.EXE (TO UNPACK)
TENSORFLOW 2 MODEL ZOO (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)
TENSORFLOW VERSION 2.3.1 
LABELLIMG.EXE
JUPYTER NOTEBOOK (TO EVALUATE THE TRAINING ON NEW IMAGES)
OTHER PYTHON LIBRARIES AS REQUIRED (PIL, MATPLOTLIB, etc...)- JUST DOWNLOAD FROM PIP

Recommended, but optional - test if everything is installed correctly 
python object_detection/builders/model_builder_tf2_test.py

Pre-step - CLONE THE MASTER BRANCH OF THE TENSORFLOW MODELS DIRECTORY
git clone https://github.com/tensorflow/models

Docker Installation - Optional (not done)

1. Unpack protos folder using protoc by running this on the cmd in the research folder:
protoc object_detection/protos/*.proto --python_out=.

2. Gather data from the Internet, then use a script to rename and resize the images 

3. Label the images using labellimg

3. Split the images into test/train folders

4. Create the label map (mask_label_map.pbtxt) 

5. Edit the model'S pipeline.config file and EDIT THE FOLLOWING PARAMETERS:
5a. num_classes: [CHANGE TO HOW MANY CLASSES YOUR MODEL SHOULD DETECT]
5b. batch_size: [REDUCED TO 1 IN MY CASE, BUT DEPENDS ON HOW MUCH YOUR SYSTEM CAN HANDLE]
5c. fine_tune_checkpoint: [PATH TO YOUR CKPT FILE]
5d. fine_tune_checkpoint_type: [CHANGE TO "detection"] 
5e. train_input_reader label_map_path: [PATH TO YOUR LABEL MAP]
5f. train_input_reader input_path: [PATH TO TRAIN.RECORD] 
5g. eval_input_reader label_map_path: [PATH TO YOUR LABEL MAP]
5h. eval_input_reader input_path: [PATH TO TEST.RECORD] 

6. Generate train.record and test.record via tfrecords 

python generate_tfrecord.py -x object_detection\\images\\train -l object_detection\\training\mask_label_map.pbtxt -o object_detection\\train.record
python generate_tfrecord.py -x object_detection\\images\test -l object_detection\\training\mask_label_map.pbtxt -o object_detection\\test.record

7. Begin training

python model_main_tf2.py --model_dir=object_detection/faster_rcnn_resnet101_v1_640x640_coco17_tpu-8 --pipeline_config_path=object_detection/training/pipeline_fasterrcnn.config --alsologtostderr --alsologtostderr
python model_main_tf2.py --model_dir=object_detection/efficientdet_d1_coco17_tpu-32 --pipeline_config_path=object_detection/training/pipeline_efficientdet.config --alsologtostderr
** Sometimes may get PermissionError - make sure the folder's "Read Only" box is unchecked!

8. Export Inference Graph (for some reason, my checkpoint is saved in a folder that is automatically named "=". Thus, my trained_checkpoint_dir is actually "=\", but the folder can be re-named after training has stopped)

python exporter_main_v2.py --input_type image_tensor --pipeline_config_path=object_detection\training\pipeline_fasterrcnn.config --trained_checkpoint_dir==\ --output_directory=object_detection\training

*This will generate a "saved_model" folder in the object_detection/training/ directory, which will be used to evaluate the model

9. Detect with object_detection_tutorial.ipynb - change the PATHS respectively